{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.signal as sng\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg=pd.read_csv('извлеченные_ээг/eeg_S01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#electrodes=np.delete(eeg.columns, [0, 1, -1, -2, -3])\n",
    "electrodes=['P3', 'C3', 'F3', 'Fz', 'F4', 'C4', 'P4', 'Cz', 'Pz', 'Fp1', 'Fp2', 'T3', 'T5', 'O1', 'O2', 'F7', 'F8', 'T6', 'T4']\n",
    "fs=300 #частота дискретизации ээг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Почему-то данные в виде строки, так что нужно перегнать обратно в числа#\n",
    "def THE_MOST_STUPID_FUNCTION(eeg_producta):\n",
    "    list_eeg={}\n",
    "    for i in electrodes:\n",
    "        eeg_producta_i=np.delete(np.array(eeg_producta[i].split('[')), [0, 1])\n",
    "        s=[]\n",
    "        for j in range(len(eeg_producta_i)):\n",
    "            vrem=eeg_producta_i[j].split(',')[:-1]\n",
    "            vrem[-1]=vrem[-1][:-1]\n",
    "            for k in range(len(vrem)):\n",
    "                vrem[k]=float(vrem[k])\n",
    "            s.append(vrem)\n",
    "        list_eeg[f'{i}']=s\n",
    "    return list_eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделим частоты и спектральные плотности мощности (psd)#\n",
    "def get_welt(eeg_producta, fs=300):\n",
    "    product_elecrod_psd={}\n",
    "    #electrodes=['P3', 'C3', 'F3', 'Fz', 'F4', 'C4', 'P4', 'Cz', 'Pz', 'Fp1', 'Fp2', 'T3', 'T5', 'O1', 'O2', 'F7', 'F8', 'T6', 'T4']\n",
    "    electrodes=['F3', 'F4'] #Что за электроды AF3 и AF4??????????????#\n",
    "    for i in electrodes:\n",
    "        eeg_i=eeg_producta[i]\n",
    "        a=[]\n",
    "        b=[]\n",
    "        g=[]\n",
    "        t=[]\n",
    "        for j in eeg_i:\n",
    "            welt=sng.welch(j, fs=fs)\n",
    "            freq=welt[0]\n",
    "            psd=welt[1]\n",
    "\n",
    "            alpha_freq=freq[freq>8]\n",
    "            alpha_freq=alpha_freq[alpha_freq<13]\n",
    "            if len(alpha_freq)!=0:\n",
    "                start=np.where(freq==alpha_freq[0])\n",
    "                stop=np.where(freq==alpha_freq[-1])\n",
    "                alpha_psd=psd[start[0][0]:stop[0][0]+1]\n",
    "                a.append({'freq_alpha_diapazon': alpha_freq, 'psd': alpha_psd})\n",
    "            \n",
    "            beta_freq=freq[freq>13]\n",
    "            beta_freq=beta_freq[beta_freq<22]\n",
    "            if len(beta_freq)!=0:\n",
    "                start=np.where(freq==beta_freq[0])\n",
    "                stop=np.where(freq==beta_freq[-1])\n",
    "                beta_psd=psd[start[0][0]:stop[0][0]+1]\n",
    "                b.append({'freq_beta_diapazon': beta_freq, 'psd': beta_psd}) #ДОБАВИТЬ КУДА_НИБудь#\n",
    "\n",
    "            gamma_freq=freq[freq>22]\n",
    "            gamma_freq=gamma_freq[gamma_freq<30]\n",
    "            if len(gamma_freq)!=0:\n",
    "                start=np.where(freq==gamma_freq[0])\n",
    "                stop=np.where(freq==gamma_freq[-1])\n",
    "                gamma_psd=psd[start[0][0]:stop[0][0]+1]\n",
    "                g.append({'freq_gamma_diapazon': gamma_freq, 'psd': gamma_psd}) #ДОБАВИТЬ КУДА_НИБудь#\n",
    "\n",
    "            theta_freq=freq[freq>4]\n",
    "            theta_freq=theta_freq[theta_freq<8]\n",
    "            if len(theta_freq)!=0:\n",
    "                start=np.where(freq==theta_freq[0])\n",
    "                stop=np.where(freq==theta_freq[-1])\n",
    "                theta_psd=psd[start[0][0]:stop[0][0]+1]\n",
    "                t.append({'freq_theta_diapazon': theta_freq, 'psd': theta_psd}) #ДОБАВИТЬ КУДА_НИБудь#\n",
    "\n",
    "        product_elecrod_psd[f'{i}']=[a, b, g, t]\n",
    "    return product_elecrod_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#То же, но для всех продуктов#\n",
    "def get_all_psd(eeg):\n",
    "    s={}\n",
    "    for i in range(len(eeg)):\n",
    "        eeg_producta=eeg.loc[i]\n",
    "        krivie_ruki=THE_MOST_STUPID_FUNCTION(eeg_producta=eeg_producta)\n",
    "        pp=eeg['product_page'].loc[i]\n",
    "        pn=eeg['product_number'].loc[i]\n",
    "        \n",
    "        eeg_psded=get_welt(krivie_ruki)\n",
    "        s[f'{pp} {pn}']=[eeg['index'].loc[i], eeg['info'].loc[i], eeg_psded]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evrika=get_all_psd(eeg=eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'freq_theta_diapazon': array([4.6875  , 5.859375, 7.03125 ]),\n",
       "  'psd': array([4.89327469, 1.75098359, 1.53925382])},\n",
       " {'freq_theta_diapazon': array([4.54545455]), 'psd': array([1.84628761])},\n",
       " {'freq_theta_diapazon': array([4.87804878, 7.31707317]),\n",
       "  'psd': array([0.75336399, 1.48854081])}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evrika['Page1 0'][2]['F3'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Егор\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Егор\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#Усредним все psd для каждого продукта как в каждом временном отрезке наблюдения, так и по всем ним#\n",
    "\n",
    "#Я НЕ ВЫКИДЫВАЛ ВРЕМЕННЫЕ ОТРЕЗКИ НАБЛЮДЕНИЯ КОНКРЕТНОГО ПРОДУКТА, КОТОРЫЕ ЯВНО КОРОЧЕ ОСТАЛЬНЫХ#\n",
    "\n",
    "def averager(eeg_pesded):\n",
    "    diapazons=['alpha', 'beta', 'gamma', 'theta']\n",
    "    for i in eeg_pesded:\n",
    "        eeg_page_prod=eeg_pesded[i][2]\n",
    "        electrodes=['F3', 'F4'] \n",
    "        for k in electrodes:\n",
    "            for indx, diap in enumerate(diapazons):\n",
    "                vrem=[]\n",
    "                for j in range(len(eeg_page_prod[k][indx])):\n",
    "                    #if len(eeg_page_prod[k][j]['psd'])>2:\n",
    "                    #    evrika[i][2][k][j][f'mean_psd_{k}']=np.mean(eeg_page_prod[k][j]['psd'])\n",
    "                    #    vrem.append(np.mean(eeg_page_prod[k][j]['psd']))\n",
    "                    evrika[i][2][k][indx][j][f'mean_psd_{k}']=np.mean(eeg_page_prod[k][indx][j]['psd'])\n",
    "                    vrem.append(np.mean(eeg_page_prod[k][indx][j]['psd']))\n",
    "                evrika[i][2][f'{k}_{diap}_average_all_of_saw']=round(np.mean(vrem), ndigits=5)\n",
    "averager(evrika)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посчитаем фронтальную альфа-ассиметрию (aw) для каждого продукта#\n",
    "def get_AW(eeg_avereged):\n",
    "    s=[]\n",
    "    inf=[]\n",
    "    for i in eeg_avereged:\n",
    "        mean_page_prod=eeg_avereged[i][2]\n",
    "        aw_prod=float((mean_page_prod['F4_alpha_average_all_of_saw']-mean_page_prod['F3_alpha_average_all_of_saw'])/(mean_page_prod['F4_alpha_average_all_of_saw']+mean_page_prod['F3_alpha_average_all_of_saw']))\n",
    "        s.append(round(aw_prod, ndigits=5))\n",
    "        inf.append(int(eeg_avereged[i][1][11]))\n",
    "    return [s, inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Ram12_valence(eeg_avereged):\n",
    "    s=[]\n",
    "    inf=[]\n",
    "    for i in eeg_avereged:\n",
    "        mean_page_prod=eeg_avereged[i][2]\n",
    "        r12_val_prod=float(mean_page_prod['F4_alpha_average_all_of_saw']-mean_page_prod['F3_beta_average_all_of_saw'])\n",
    "        s.append(round(r12_val_prod, ndigits=5))\n",
    "        inf.append(int(eeg_avereged[i][1][11]))\n",
    "    return [s, inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Ram15_valence(eeg_avereged):\n",
    "    s=[]\n",
    "    inf=[]\n",
    "    for i in eeg_avereged:\n",
    "        mean_page_prod=eeg_avereged[i][2]\n",
    "        r15_val_prod=float((mean_page_prod['F4_alpha_average_all_of_saw']/mean_page_prod['F4_beta_average_all_of_saw'])-(mean_page_prod['F3_alpha_average_all_of_saw']/mean_page_prod['F3_beta_average_all_of_saw']))\n",
    "        s.append(round(r15_val_prod, ndigits=5))\n",
    "        inf.append(int(eeg_avereged[i][1][11]))\n",
    "    return [s, inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effort_index1(eeg_avereged):\n",
    "    s=[]\n",
    "    inf=[]\n",
    "    for i in eeg_avereged:\n",
    "        mean_page_prod=eeg_avereged[i][2]\n",
    "        ef_prod=float((mean_page_prod['F4_theta_average_all_of_saw']-mean_page_prod['F3_theta_average_all_of_saw'])/(mean_page_prod['F4_theta_average_all_of_saw']+mean_page_prod['F3_theta_average_all_of_saw']))\n",
    "        s.append(round(ef_prod, ndigits=5))\n",
    "        inf.append(int(eeg_avereged[i][1][11]))\n",
    "    return [s, inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "hell_aw=get_AW(evrika)\n",
    "hell_val12=get_Ram12_valence(evrika)\n",
    "hell_val15=get_Ram15_valence(evrika)\n",
    "hell_effort=get_effort_index1(evrika)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aw=pd.DataFrame({'product_page_number': list(evrika)})\n",
    "df_aw['aw']=hell_aw[0]\n",
    "df_aw['buy']=hell_aw[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val12=pd.DataFrame({'product_page_number': list(evrika)})\n",
    "df_val12['val12']=hell_val12[0]\n",
    "df_val12['buy']=hell_val12[1]\n",
    "\n",
    "df_val15=pd.DataFrame({'product_page_number': list(evrika)})\n",
    "df_val15['val15']=hell_val15[0]\n",
    "df_val15['buy']=hell_val15[1]\n",
    "\n",
    "df_effort=pd.DataFrame({'product_page_number': list(evrika)})\n",
    "df_effort['effort']=hell_effort[0]\n",
    "df_effort['buy']=hell_effort[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 126 entries, 0 to 131\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   product_page_number  126 non-null    object \n",
      " 1   aw                   126 non-null    float64\n",
      " 2   buy                  126 non-null    int64  \n",
      " 3   val12                126 non-null    float64\n",
      " 4   val15                126 non-null    float64\n",
      " 5   effort               126 non-null    float64\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df=df_aw.merge(df_val12)\n",
    "df=df.merge(df_val15)\n",
    "df=df.merge(df_effort)\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns=['product_page_number', 'buy', 'val12', 'val15', 'effort'])\n",
    "y=df.drop(columns=['product_page_number', 'aw', 'val12', 'val15', 'effort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Егор\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Посмотрим, может быть и получилось#\n",
    "LR=LogisticRegression()\n",
    "LR.fit(x_train, y_train)\n",
    "y_predict_LR=LR.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_predict_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сделаем для всех испытуемых#\n",
    "people=['01', '02', '03', '05', '06', '07', '08', '09', '10', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44']\n",
    "electrodes=['P3', 'C3', 'F3', 'Fz', 'F4', 'C4', 'P4', 'Cz', 'Pz', 'Fp1', 'Fp2', 'T3', 'T5', 'O1', 'O2', 'F7', 'F8', 'T6', 'T4']\n",
    "fs=300 #частота дискретизации ээг\n",
    "df=pd.DataFrame()\n",
    "\n",
    "for t in people:\n",
    "        eeg=pd.read_csv(f'извлеченные_ээг/eeg_S{t}.csv')\n",
    "        evrika=get_all_psd(eeg=eeg)\n",
    "        averager(evrika)\n",
    "\n",
    "        hell_aw=get_AW(evrika)\n",
    "        hell_val12=get_Ram12_valence(evrika)\n",
    "        hell_val15=get_Ram15_valence(evrika)\n",
    "        hell_effort=get_effort_index1(evrika)\n",
    "        df_val12=pd.DataFrame({'product_page_number': list(evrika)})\n",
    "        df_val12['val12']=hell_val12[0]\n",
    "        df_val12['buy']=hell_val12[1]\n",
    "        df_val15=pd.DataFrame({'product_page_number': list(evrika)})\n",
    "        df_val15['val15']=hell_val15[0]\n",
    "        df_val15['buy']=hell_val15[1]\n",
    "        df_effort=pd.DataFrame({'product_page_number': list(evrika)})\n",
    "        df_effort['effort']=hell_effort[0]\n",
    "        df_effort['buy']=hell_effort[1]\n",
    "\n",
    "        df_people=pd.DataFrame({'people': np.full(len(list(evrika)), t), 'product_page_number': list(evrika)})\n",
    "        df_people['aw']=hell_aw[0]\n",
    "        df_people['buy']=hell_aw[1]\n",
    "        df_people=df_people.merge(df_val12)\n",
    "        df_people=df_people.merge(df_val15)\n",
    "        df_people=df_people.merge(df_effort)\n",
    "        \n",
    "        df=pd.concat([df, df_people])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def aw_God(directory='извлеченные_ээг'):\n",
    "#    people=['01', '02', '03', '05', '06', '07', '08', '09', '10', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44']\n",
    "#    electrodes=['P3', 'C3', 'F3', 'Fz', 'F4', 'C4', 'P4', 'Cz', 'Pz', 'Fp1', 'Fp2', 'T3', 'T5', 'O1', 'O2', 'F7', 'F8', 'T6', 'T4']\n",
    "#    fs=300 #частота дискретизации ээг\n",
    "#    df=pd.DataFrame()\n",
    "#    for t in people:\n",
    "#        eeg=pd.read_csv(f'{directory}/eeg_S{t}.csv')\n",
    "#        evrika=get_all_psd(eeg=eeg)\n",
    "#        averager(evrika)\n",
    "#        hell=get_AW(evrika)\n",
    "#        df_people=pd.DataFrame({'people': np.full(len(list(evrika)), t), 'product_page_number': list(evrika)})\n",
    "#        df_people['aw']=hell[0]\n",
    "#        df_people['buy']=hell[1]\n",
    "#        df=pd.concat(df, df_people)\n",
    "#    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people</th>\n",
       "      <th>product_page_number</th>\n",
       "      <th>aw</th>\n",
       "      <th>buy</th>\n",
       "      <th>val12</th>\n",
       "      <th>val15</th>\n",
       "      <th>effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Page1 0</td>\n",
       "      <td>-0.21720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05437</td>\n",
       "      <td>-0.81024</td>\n",
       "      <td>0.14033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>Page1 1</td>\n",
       "      <td>0.30423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.18803</td>\n",
       "      <td>1.10880</td>\n",
       "      <td>0.05269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>Page1 2</td>\n",
       "      <td>0.15855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06618</td>\n",
       "      <td>-0.14021</td>\n",
       "      <td>0.52483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>Page1 3</td>\n",
       "      <td>-0.13846</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89158</td>\n",
       "      <td>-0.89813</td>\n",
       "      <td>0.22057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>Page1 4</td>\n",
       "      <td>0.06312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47358</td>\n",
       "      <td>-0.08872</td>\n",
       "      <td>0.01328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>44</td>\n",
       "      <td>Page6 19</td>\n",
       "      <td>-0.12071</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.08974</td>\n",
       "      <td>0.30855</td>\n",
       "      <td>-0.32381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>44</td>\n",
       "      <td>Page6 20</td>\n",
       "      <td>-0.10263</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.45575</td>\n",
       "      <td>-0.04902</td>\n",
       "      <td>-0.20760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>44</td>\n",
       "      <td>Page6 21</td>\n",
       "      <td>0.11665</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.15555</td>\n",
       "      <td>0.25523</td>\n",
       "      <td>0.21105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>44</td>\n",
       "      <td>Page6 22</td>\n",
       "      <td>0.27023</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70788</td>\n",
       "      <td>-0.05353</td>\n",
       "      <td>0.52069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>44</td>\n",
       "      <td>Page6 23</td>\n",
       "      <td>0.04520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15303</td>\n",
       "      <td>-0.22811</td>\n",
       "      <td>0.43889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5902 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    people product_page_number       aw  buy    val12    val15   effort\n",
       "0       01             Page1 0 -0.21720    0  0.05437 -0.81024  0.14033\n",
       "1       01             Page1 1  0.30423    0  0.18803  1.10880  0.05269\n",
       "2       01             Page1 2  0.15855    0  0.06618 -0.14021  0.52483\n",
       "3       01             Page1 3 -0.13846    1  0.89158 -0.89813  0.22057\n",
       "4       01             Page1 4  0.06312    0  0.47358 -0.08872  0.01328\n",
       "..     ...                 ...      ...  ...      ...      ...      ...\n",
       "137     44            Page6 19 -0.12071    1 -0.08974  0.30855 -0.32381\n",
       "138     44            Page6 20 -0.10263    0 -0.45575 -0.04902 -0.20760\n",
       "139     44            Page6 21  0.11665    0 -0.15555  0.25523  0.21105\n",
       "140     44            Page6 22  0.27023    0  0.70788 -0.05353  0.52069\n",
       "141     44            Page6 23  0.04520    0  0.15303 -0.22811  0.43889\n",
       "\n",
       "[5902 rows x 7 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('eeg_aw_try3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5606 entries, 0 to 5901\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           5606 non-null   int64  \n",
      " 1   people               5606 non-null   int64  \n",
      " 2   product_page_number  5606 non-null   object \n",
      " 3   aw                   5606 non-null   float64\n",
      " 4   buy                  5606 non-null   int64  \n",
      " 5   val12                5606 non-null   float64\n",
      " 6   val15                5606 non-null   float64\n",
      " 7   effort               5606 non-null   float64\n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 394.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('eeg_aw_valence_effort.csv')\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим, может быть и получилось#\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "x=df.drop(columns=['product_page_number', 'buy', 'Unnamed: 0', 'people', 'aw', 'val12', 'val15'])\n",
    "y=df.drop(columns=['product_page_number', 'Unnamed: 0', 'people', 'aw', 'val12', 'val15', 'effort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8556149732620321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Егор\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "LR=LogisticRegression()\n",
    "LR.fit(x_train, y_train)\n",
    "y_predict_LR=LR.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_predict_LR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
